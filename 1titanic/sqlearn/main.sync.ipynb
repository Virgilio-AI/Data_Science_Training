{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907f73cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "674a1eb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m randint\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \u001b[38;5;66;03m# for importing numpy\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \u001b[38;5;66;03m# for importing pandas\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "from numpy.random import randint\n",
    "import numpy as np # for importing numpy\n",
    "import pandas as pd # for importing pandas\n",
    "from sklearn.utils import shuffle # for shuffling the data\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da949da1",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c847cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21b554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train.head())\n",
    "display(train.describe())\n",
    "display(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad3415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot1dpie(ax,labels_values, labels, title, x,y):\n",
    "\tax[y].pie(labels_values, labels = labels, autopct='%1.1f%%', shadow = True, startangle = 90)\n",
    "\tax[y].title.set_text(title)\n",
    "\n",
    "def plot2dpie(ax,labels_values, labels, title,x,y):\n",
    "\t# ca\n",
    "\tax[x,y].pie(labels_values, labels = labels, autopct='%1.1f%%', shadow = True, startangle = 90)\n",
    "\tax[x,y].title.set_text(title)\n",
    "\n",
    "\n",
    "def plotpie(x,y,ax,labels_values, labels, title):\n",
    "\t# check if ax is 2d or 1d\n",
    "\tif len(ax.shape) == 1:\n",
    "\t\tplot1dpie(ax,labels_values, labels, title, x,y)\n",
    "\telse:\n",
    "\t\tplot2dpie(ax,labels_values, labels, title,x,y)\n",
    "\n",
    "def multipie(data, titles, target_col, labels, array_cols, icols = -1, irows = -1, pivot_column = None):\n",
    "\t\"\"\"\n",
    "\t%%\n",
    "\tdata in the form of \n",
    "\t\n",
    "\t|Survived|1  |2 |3  |\n",
    "\t|1       |136|87|119|\n",
    "\t|1       |80 |97|372|\n",
    "\t\n",
    "\ttitles = ['1 survival rate','2 survival rate','3 survival rate']\n",
    "\ttarget_col = 'Survived'\n",
    "\tlabels = ['Survived','Died']\n",
    "\tarray_cols = ['1','2','3']\n",
    "\ticols, irows = 2,2\n",
    "\tpivot_column = 'Pclass' -- if Not None, then the data will be pivoted\n",
    "\t\"\"\"\n",
    "\n",
    "\tif pivot_column is not None:\n",
    "\t\ttmp = data.pivot_table(index = target_col, columns = pivot_column, aggfunc = 'size',fill_value = 0).reset_index()\n",
    "\t\ttmp = tmp.rename_axis(None, axis = 1)\n",
    "\t\tdata = tmp\n",
    "\n",
    "\n",
    "\tinput_cols = len(array_cols) + 1\n",
    "\tif icols == -1:\n",
    "\t\tncols = 3\n",
    "\telse:\n",
    "\t\tncols = icols\n",
    "\n",
    "\tif irows == -1:\n",
    "\t\tnrows = (input_cols - 1) // ncols  + 1\n",
    "\telse:\n",
    "\t\tnrows  = irows\n",
    "\n",
    "\tfig, ax = plt.subplots(nrows = nrows, ncols = ncols, figsize=(8,2 * nrows))\n",
    "\t# first plot the sum of the target column\n",
    "\tlabels_values = [0] * len(data)\n",
    "\t# get the sum of all the columns for each row and store it in a list\n",
    "\t# exclude the target_col column from the sums\n",
    "\n",
    "\tfor i in range(len(data)):\n",
    "\t\tfor j in range(len(array_cols)):\n",
    "\t\t\n",
    "\t\t\tcolumn = array_cols[j]\n",
    "\t\t\tlabels_values[i] += data.loc[i,column]\n",
    "\n",
    "\n",
    "\tplotpie(0,0,ax,labels_values, labels, title = 'Sum of ' + target_col)\n",
    "\t# now plot all the array_cols with the target_col individually\n",
    "\tfor i in range(1, len(array_cols) + 1):\n",
    "\t\tlabels_values = [0] * len(labels)\n",
    "\t\tfor j in range(len(data)):\n",
    "\t\t\tlabels_values[j] = data[array_cols[i-1]].iloc[j]\n",
    "\t\trow = (i) // ncols\n",
    "\t\tcol = (i) % ncols\n",
    "\t\tplotpie(row,col,ax,labels_values, labels, title = titles[i-1])\n",
    "\t# delete unused plots axes\n",
    "\tfor i in range(len(array_cols) + 1, ncols * nrows):\n",
    "\t\trow = i // ncols\n",
    "\t\tcol = i % ncols\n",
    "\t\tfig.delaxes(ax[row,col])\n",
    "\n",
    "\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0a9f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_count = train['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d2ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(survived_count, labels = ['Died','Survived'], autopct = '%1.1f%%', shadow = True, startangle = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c99a8f9",
   "metadata": {},
   "source": [
    "# Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd32178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pclass column contains the socioeconomic status of the passengers. It might be predictve for our model\n",
    "# 1 = upper\n",
    "# 2 = middle\n",
    "# 3 = lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7937956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multipie(train, ['1 survival rate','2 survival rate','3 survival rate'], 'Survived', ['Survived','Died'], [1,2,3],icols = 2, irows = 2, pivot_column = 'Pclass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad1ea96",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71270e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mr -> mister is an adult man regardless of his marital status\n",
    "# Miss -> mujer soltera\n",
    "# Mrs -> mujer casada\n",
    "# Dr -> doctor\n",
    "# Ms -> mujer ambiguo\n",
    "# col -> coronel\n",
    "# major -> major\n",
    "# Rev -> reverendo\n",
    "# Dona -> Madam\n",
    "# Master -> joven\n",
    "# Mlle -> Mademoiselle\n",
    "#\n",
    "# royalty -> Don, Jonkheer, Sir, Dona, Mlle\n",
    "# military -> Capt, Col, Major\n",
    "# single_women -> Miss, Ms\n",
    "# married_women -> Mrs\n",
    "# reverend -> Rev\n",
    "# master -> young man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b04451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we read the test data\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "# we extract the title\n",
    "test['Title'] = test['Name'].str.split(', ', expand = True)[1].str.split('.', expand = True)[0]\n",
    "train['Title'] = train['Name'].str.split(', ', expand = True)[1].str.split('.', expand = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b41c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a title_category column\n",
    "train['Title_category'] = train['Title']\n",
    "test['Title_category'] = test['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad34b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all the titles with the new categories\n",
    "# royalty -> Don, Jonkheer, Sir, Dona, Mlle\n",
    "# military -> Capt, Col, Major\n",
    "# single_women -> Miss, Ms\n",
    "# married_women -> Mrs\n",
    "# young_man -> Master\n",
    "\n",
    "full_data = [train, test]\n",
    "for data in full_data:\n",
    "\tdata['Title_category'] = data['Title_category'].replace(['Don', 'Jonkheer', 'Sir', 'Dona', 'Mlle','mme','Lady','the Countess','Mme'], 'Royalty')\n",
    "\tdata['Title_category'] = data['Title_category'].replace(['Capt', 'Col', 'Major'], 'Military')\n",
    "\tdata['Title_category'] = data['Title_category'].replace(['Miss','Ms'],'single_women')\n",
    "\tdata['Title_category'] = data['Title_category'].replace(['Mrs'],'married_women')\n",
    "\tdata['Title_category'] = data['Title_category'].replace(['Master'],'young_man')\n",
    "\tdata['Title_category'] = data['Title_category'].replace(['Rev'],'Mr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_cat_vals = train['Survived'].groupby(train['Title_category']).mean().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f684eb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the series to a dataframe\n",
    "title_cat_vals = pd.DataFrame(title_cat_vals).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4b9583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the axis for multiple pie plots\n",
    "fig, ax = plt.subplots(2,4, figsize = (10,5))\n",
    "for i in range(len(title_cat_vals)):\n",
    "\trow = i // 4\n",
    "\tcol = i % 4\n",
    "\t# plot the pie chart\n",
    "\tax[row,col].pie([1 - title_cat_vals['Survived'].iloc[i], title_cat_vals['Survived'].iloc[i]], labels = ['Died','Survived'], autopct = '%1.1f%%', shadow = True, startangle = 90)\n",
    "\tax[row,col].set_title(title_cat_vals['Title_category'].iloc[i])\n",
    "\n",
    "# clean the unused plots\n",
    "fig.delaxes(ax[1,3])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# there are 177 missing values, we will imput them in feature engineering part. Now, let's look at the distribution of ages by surviving\n",
    "# create two histplots for survived and not survived using seaborn\n",
    "survived = train[train['Survived'] == 1]\n",
    "died = train[train['Survived'] == 0]\n",
    "\n",
    "\n",
    "h1 = sns.histplot(survived['Age'], kde = True, color = 'green')\n",
    "h2 = sns.histplot(died['Age'], kde = True, color = 'red')\n",
    "h1.set_title('Age distribution by surviving')\n",
    "h1.set_xlabel('Age')\n",
    "h1.set_ylabel('Count')\n",
    "h1.legend(['Survived','Died'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is sex important for surviving?\n",
    "multipie(train, ['Male Survival','Female Survival'],'Survived',['Survived','Died'], ['male','female'], pivot_column = 'Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e362b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SibSP -> Sibling or spouse\n",
    "# Parch -> Parent or children\n",
    "# I decided to create a new feature called family_size by summing SibSp and Parch columns\n",
    "train['Family_size'] = train['SibSp'] + train['Parch']\n",
    "# proportion of people survived for each family size\n",
    "class_survived = train['Survived'].groupby(train['Family_size']).mean().sort_values(ascending = False)\n",
    "class_survived = pd.DataFrame(class_survived).reset_index()\n",
    "class_survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6240de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,3)\n",
    "for i in range(len(class_survived)):\n",
    "\trow = i // 3\n",
    "\tcol = i % 3\n",
    "\t# plot the pie chart\n",
    "\tax[row,col].pie([1 - class_survived['Survived'].iloc[i], class_survived['Survived'].iloc[i]], labels = ['Died','Survived'], autopct = '%1.1f%%', shadow = True, startangle = 90)\n",
    "\tax[row,col].set_title(class_survived['Family_size'].iloc[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9381a6d2",
   "metadata": {},
   "source": [
    "ticket\n",
    "I extracted only first letters of the tickets because I thought that they would indicate the ticket typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79a8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first letters of the tickets\n",
    "train['Ticket_first'] = train['Ticket'].apply(lambda x: str(x)[0])\n",
    "ticket_df = train.groupby('Ticket_first')['Survived'].mean().sort_values(ascending = False)\n",
    "ticket_df = pd.DataFrame(ticket_df).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98e24a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,4, figsize = (12,6))\n",
    "\n",
    "for i in range(len(ticket_df)):\n",
    "\trow = i // 4\n",
    "\tcol = i%4\n",
    "\tax[row, col].pie([1 - ticket_df['Survived'].iloc[i], ticket_df['Survived'].iloc[i]], labels = ['Died','Survived'], autopct = '%1.1f%%', shadow = True, startangle = 90)\n",
    "\tax[row,col].set_title(ticket_df['Ticket_first'].iloc[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd41f5",
   "metadata": {},
   "source": [
    "# Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5712d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can plot a histogram to see the fare distribution\n",
    "# plot the density plot of fare to the Survived\n",
    "sns.kdeplot(train['Fare'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9255fab4",
   "metadata": {},
   "source": [
    "there is also a correlation between ticket fares and surviving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804985bb",
   "metadata": {},
   "source": [
    "# cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ecc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Cabin_first'] = train['Cabin'].apply(lambda x:str(x)[0])\n",
    "# surviving rate of cabin first letters\n",
    "cabin_sur = train.groupby('Cabin_first')['Survived'].mean().sort_values(ascending = False)\n",
    "cabin_sur = pd.DataFrame(cabin_sur).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d318e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,3)\n",
    "\n",
    "for i in range(len(cabin_sur)):\n",
    "\trow = i // 3\n",
    "\tcol = i%3\n",
    "\tax[row,col].pie([1 - cabin_sur['Survived'].iloc[i],cabin_sur['Survived'].iloc[i]], labels = ['Died','Survived'], autopct = '%1.1f%%', shadow = True, startangle = 90)\n",
    "\tax[row,col].set_title(ticket_df['Ticket_first'].iloc[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ef8d71",
   "metadata": {},
   "source": [
    "# Embarked\n",
    "embarked is a categorical features which shows us the port of embarkation \n",
    "C = Cherbourg\n",
    "Q = Queensrtown\n",
    "S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3544e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['Embarked'].value_counts())\n",
    "\n",
    "# survival rates of embarked\n",
    "embarked_sur = train['Survived'].groupby(train['Embarked']).mean()\n",
    "embarked_sur = pd.DataFrame(embarked_sur).reset_index()\n",
    "embarked_sur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375e2dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3)\n",
    "\n",
    "for i in range(len(embarked_sur)):\n",
    "\tcol = i%3\n",
    "\trt = embarked_sur['Survived'].iloc[i]\n",
    "\tax[col].pie([1 - rt,rt], labels = ['Died','Survived'], autopct = '%1.1f%%', shadow = True, startangle = 90)\n",
    "\tax[col].set_title(embarked_sur['Embarked'].iloc[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a6781b",
   "metadata": {},
   "source": [
    "# feature engineering\n",
    "we have a lot from exploratory data analysis. Now we can start feature engineering. Firstly, lets load the train and test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdb9994",
   "metadata": {},
   "source": [
    "I have used two types of imputter from sklearn. iterative for age imputation, and simple imputter ( with most frequent strategy ) for embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d220c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dbedf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train.head(3))\n",
    "display(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9882dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputers\n",
    "imp_embarked = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "imp_age = IterativeImputer(max_iter = 100, random_state = 34, n_nearest_features = 2)\n",
    "\n",
    "# impute embarked\n",
    "train['Embarked'] = imp_embarked.fit_transform(train[['Embarked']])\n",
    "test['Embarked'] = imp_embarked.transform(test[['Embarked']])\n",
    "\n",
    "# impute age\n",
    "train['Age'] = np.round(imp_age.fit_transform(train[['Age']]))\n",
    "test['Age'] = np.round(imp_age.fit_transform(test[['Age']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3087abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train.head(3))\n",
    "display(train.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a9cd1a",
   "metadata": {},
   "source": [
    "we also encode the sex column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ccbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode sex\n",
    "train['Sex'] = le.fit_transform(train[['Sex']].values.ravel())\n",
    "test['Sex'] = le.fit_transform(test[['Sex']].values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc88cdd",
   "metadata": {},
   "source": [
    "in EDA, we decided to use family size feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50ae034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# family size\n",
    "train['Fsize'] = train['SibSp'] + train['Parch']\n",
    "test['Fsize'] = test['SibSp'] + test['Parch']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8533fd",
   "metadata": {},
   "source": [
    "ticket first letters and cabin first letters are also needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b231e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticket first letters\n",
    "train['Ticket'] = train['Ticket'].apply(lambda x: str(x)[0])\n",
    "test['Ticket'] = test['Ticket'].apply(lambda x: str(x)[0])\n",
    "\n",
    "# cabin first letters\n",
    "train['Cabin'] = train['Cabin'].apply(lambda x: str(x)[0])\n",
    "test['Cabin'] = test['Cabin'].apply(lambda x: str(x)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fa0c77",
   "metadata": {},
   "source": [
    "now we need some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e08ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_passenger_label(family_size):\n",
    "\tif family_size == 0:\n",
    "\t\treturn \"Alone\"\n",
    "\telif family_size <= 3:\n",
    "\t\treturn \"Small Family\"\n",
    "\telse:\n",
    "\t\treturn \"Big_Family\"\n",
    "\n",
    "# group the ticket column\n",
    "def assign_label_ticket(first):\n",
    "\tif first in [\"F\",'1','P','9']:\n",
    "\t\treturn \"Ticket_high\"\n",
    "\telif first in ['S','C','2']:\n",
    "\t\treturn \"Ticket_medium\"\n",
    "\telse:\n",
    "\t\treturn \"Ticket_low\"\n",
    "\n",
    "# Group the Cabin column  \n",
    "def assign_label_cabin(cabin):\n",
    "\tif cabin in [\"D\", \"E\", \"B\", \"F\", \"C\"]:\n",
    "\t\treturn \"Cabin_high\"\n",
    "\telif cabin in [\"G\", \"A\"]:\n",
    "\t\treturn \"Cabin_middle\"\n",
    "\telse:\n",
    "\t\treturn \"Cabin_low\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c475db1",
   "metadata": {},
   "source": [
    "apply the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bd54bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb9b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# family size\n",
    "train['Fsize'] = train['Fsize'].apply(assign_passenger_label)\n",
    "test['Fsize'] = test['Fsize'].apply(assign_passenger_label)\n",
    "\n",
    "# ticket\n",
    "train['Ticket'] = train['Ticket'].apply(assign_label_ticket)\n",
    "test['Ticket'] = test['Ticket'].apply(assign_label_ticket)\n",
    "\n",
    "# cabin\n",
    "train['Cabin'] = train['Cabin'].apply(assign_label_cabin)\n",
    "test['Cabin'] = test['Cabin'].apply(assign_label_cabin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bece0a5a",
   "metadata": {},
   "source": [
    "its time to use one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc6d9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(columns = ['Pclass','Embarked','Ticket','Cabin','Title_category','Fsize'], data = train, drop_first = True)\n",
    "test = pd.get_dummies(columns = ['Pclass','Embarked','Ticket','Cabin','Title_category','Fsize'], data = test, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78232295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the unecessry columns\n",
    "target = train[\"Survived\"]\n",
    "train.drop([\"Survived\", \"SibSp\", \"Parch\", \"Name\", \"PassengerId\",'Title','Ticket_first','Cabin_first','Family_size'], axis=1, inplace=True)\n",
    "test.drop([\"SibSp\", \"Parch\", \"Name\",\"PassengerId\",'Title',], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e6e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbd467c",
   "metadata": {},
   "source": [
    "#machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1378ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select the features and the target\n",
    "X = train.values\n",
    "y = target.values\n",
    "\n",
    "# Split the data info training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=34, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25493819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# Initialize a RandomForestClassifier\n",
    "#rf = RandomForestClassifier(random_state=34)\n",
    "\n",
    "#params = {'n_estimators': [50, 100, 200, 300, 350],\n",
    "#          'max_depth': [3,4,5,7, 10,15,20],\n",
    "#          'criterion':['entropy', 'gini'],\n",
    "#          'min_samples_leaf' : [1, 2, 3, 4, 5, 10],\n",
    "#          'max_features':['sqrt'],\n",
    "#          'min_samples_split': [3, 5, 10, 15, 20],\n",
    "#          'max_leaf_nodes':[2,3,4,5],\n",
    "#          }\n",
    "\n",
    "#clf = GridSearchCV(estimator=rf,param_grid=params,cv=10, n_jobs=-1)\n",
    "\n",
    "#clf.fit(X_train, y_train.ravel())\n",
    "\n",
    "#print(clf.best_estimator_)\n",
    "#print(clf.best_score_)\n",
    "\n",
    "#rf_best = clf.best_estimator_\n",
    "\n",
    "# Predict from the test set\n",
    "#y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the accuracy with accuracy_score function\n",
    "#print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "#print(\"\\nConfusion Matrix\\n\")\n",
    "#print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62deb796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas series with feature importances\n",
    "#importance = pd.Series(rf_best.feature_importances_,index=train.columns).sort_values(ascending=False)\n",
    "\n",
    "#sns.barplot(x=importance, y=importance.index)\n",
    "# Add labels to your graph\n",
    "#plt.xlabel('Importance')\n",
    "#plt.ylabel('Feature')\n",
    "#plt.title(\"Important Features\")\n",
    "#plt.show()\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "Image(\"fimp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61902ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_clf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=4, max_features='auto',\n",
    "                       max_leaf_nodes=5, max_samples=None,\n",
    "                       min_impurity_decrease=0.0,\n",
    "                       min_samples_leaf=1, min_samples_split=15,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=350,\n",
    "                       n_jobs=None, oob_score=True, random_state=34, verbose=0,\n",
    "                       warm_start=False)\n",
    "\n",
    "last_clf.fit(train, target)\n",
    "print(\"%.4f\" % last_clf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaaef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store passenger ids\n",
    "ids = pd.read_csv(\"../data/test.csv\")[[\"PassengerId\"]].values\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8903dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the mean into the missing value\n",
    "test['Fare'].fillna(train['Fare'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = last_clf.predict(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff149e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with passenger ids and predictions\n",
    "df = {'PassengerId': ids.ravel(), 'Survived':predictions}\n",
    "\n",
    "# Create a DataFrame named submission\n",
    "submission = pd.DataFrame(df)\n",
    "\n",
    "\n",
    "# Save the file\n",
    "submission.to_csv(\"submission_last.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cffabf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract single tree\n",
    "estimator = last_clf.estimators_[5]\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c28162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Image(filename = 'tree.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
